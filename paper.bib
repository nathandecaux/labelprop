@article{albu2008morphology,
	title = {A morphology-based approach for interslice interpolation of anatomical slices from volumetric images},
	volume = {55},
	doi = {10/fp7xpw},
	number = {8},
	journal = {IEEE Transactions on Biomedical Engineering},
	author = {Albu, Alexandra Branzan and Beugeling, Trevor and Laurendeau, Denis},
	year = {2008},
	pages = {2022--2038},
}

@inproceedings{ronneberger2015u,
  title={U-net: Convolutional networks for biomedical image segmentation},
  author={Ronneberger, Olaf and Fischer, Philipp and Brox, Thomas},
  booktitle={Medical Image Computing and Computer-Assisted Intervention--MICCAI 2015: 18th International Conference, Munich, Germany, October 5-9, 2015, Proceedings, Part III 18},
  pages={234--241},
  year={2015},
  doi = {10.1007/978-3-319-24574-4_28},
  organization={Springer}
}

@misc{jabri_space-time_2020,
	title = {Space-{Time} {Correspondence} as a {Contrastive} {Random} {Walk}},
	url = {http://arxiv.org/abs/2006.14613},
	doi = {10.48550/arXiv.2006.14613},
	abstract = {This paper proposes a simple self-supervised approach for learning a representation for visual correspondence from raw video. We cast correspondence as prediction of links in a space-time graph constructed from video. In this graph, the nodes are patches sampled from each frame, and nodes adjacent in time can share a directed edge. We learn a representation in which pairwise similarity defines transition probability of a random walk, so that long-range correspondence is computed as a walk along the graph. We optimize the representation to place high probability along paths of similarity. Targets for learning are formed without supervision, by cycle-consistency: the objective is to maximize the likelihood of returning to the initial node when walking along a graph constructed from a palindrome of frames. Thus, a single path-level constraint implicitly supervises chains of intermediate comparisons. When used as a similarity metric without adaptation, the learned representation outperforms the self-supervised state-of-the-art on label propagation tasks involving objects, semantic parts, and pose. Moreover, we demonstrate that a technique we call edge dropout, as well as self-supervised adaptation at test-time, further improve transfer for object-centric correspondence.},
	urldate = {2023-09-08},
	publisher = {arXiv},
	author = {Jabri, Allan and Owens, Andrew and Efros, Alexei A.},
	month = dec,
	year = {2020},
	note = {arXiv:2006.14613 [cs, eess]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Electrical Engineering and Systems Science - Image and Video Processing},
}

@article{decaux_semi-automatic_2023,
	title = {Semi-automatic muscle segmentation in {MR} images using deep registration-based label propagation},
	volume = {140},
	issn = {0031-3203},
	url = {https://www.sciencedirect.com/science/article/pii/S0031320323002297},
	doi = {10.1016/j.patcog.2023.109529},
	abstract = {Fully automated approaches based on convolutional neural networks have shown promising performances on muscle segmentation from magnetic resonance (MR) images, but still rely on an extensive amount of training data to achieve valuable results. Muscle segmentation for pediatric and rare diseases cohorts is therefore still often done manually. Producing dense delineations over 3D volumes remains a time-consuming and tedious task, with significant redundancy between successive slices. In this work, we propose a segmentation method relying on registration-based label propagation, which provides 3D muscle delineations from a limited number of annotated 2D slices. Based on an unsupervised deep registration scheme, our approach ensures the preservation of anatomical structures by penalizing deformation compositions that do not produce consistent segmentation from one annotated slice to another. Evaluation is performed on MR data from lower leg and shoulder joints. Results demonstrate that the proposed semi-automatic multi-label segmentation model outperforms state-of-the-art techniques.},
	urldate = {2023-10-16},
	journal = {Pattern Recognition},
	author = {Decaux, Nathan and Conze, Pierre-Henri and Ropars, Juliette and He, Xinyan and Sheehan, Frances T. and Pons, Christelle and Ben Salem, Douraied and Brochard, Sylvain and Rousseau, François},
	month = aug,
	year = {2023},
	keywords = {Deep registration, Label propagation, Musculoskeletal system, Semi-automatic segmentation},
	pages = {109529},
}

@article{conze2020healthy,
	title = {Healthy versus pathological learning transferability in shoulder muscle {MRI} segmentation using deep convolutional encoder-decoders},
	volume = {83},
	doi = {10/gpjrzf},
	journal = {Computerized Medical Imaging and Graphics},
	author = {Conze, Pierre-Henri and Brochard, Sylvain and Burdin, Valérie and Sheehan, Frances T and Pons, Christelle},
	year = {2020},
	pages = {101733},
}

@inproceedings{vadineanu_analysis_2022,
	title = {An {Analysis} of the {Impact} of {Annotation} {Errors} on the {Accuracy} of {Deep} {Learning} for {Cell} {Segmentation}},
	url = {https://proceedings.mlr.press/v172/vadineanu22a.html},
	abstract = {Recent studies have shown that there can be high inter- and intra-observer variability when creating annotations for biomedical image segmentation. To mitigate the effects of manual annotation variability when training machine learning algorithms, various methods have been developed. However, little work has been done on actually assessing the impact of annotation errors on machine learning-based segmentation. For the task of cell segmentation, our work aims to bridge this gap by providing a thorough analysis of three types of potential annotation errors. We tackle the limitation of previous studies that lack a golden standard ground truth by performing our analysis on two synthetically-generated data sets with perfect labels, while also validating our observations on manually-labeled data. Moreover, we discuss the influence of the annotation errors on the results of three different network architectures: UNet, SegNet, and MSD. We find that UNet shows the overall best robustness for all data sets on two categories of errors, especially when the severity of the error is low, while MSD generalizes well even when a large proportion of the cell labels is missing during training. Moreover, we observe that special care should be taken to avoid wrongly labeling large objects when the target cells have small footprints.},
	language = {en},
	urldate = {2023-12-15},
	booktitle = {Proceedings of {The} 5th {International} {Conference} on {Medical} {Imaging} with {Deep} {Learning}},
	publisher = {PMLR},
	author = {Vădineanu, Şerban and Pelt, Daniël Maria and Dzyubachyk, Oleh and Batenburg, Kees Joost},
	doi = {10.3252/2022.07.22},
	month = dec,
	year = {2022},
	note = {ISSN: 2640-3498},
	pages = {1251--1267},
}

@article{sakinis2019interactive,
	title = {Interactive segmentation of medical images through fully convolutional neural networks},
	journal = {arXiv preprint arXiv:1903.08205},
	author = {Sakinis, Tomas and Milletari, Fausto and Roth, Holger and Korfiatis, Panagiotis and Kostandy, Petro and Philbrick, Kenneth and Akkus, Zeynettin and Xu, Ziyue and Xu, Daguang and Erickson, Bradley J},
	year = {2019},
	doi = {10.48550/arXiv.1903.08205},
	keywords = {⛔ No DOI found},
}

@article{zhang2021interactive,
	title = {Interactive medical image segmentation via a point-based interaction},
	volume = {111},
	doi = {10/gqg5d6},
	journal = {Artificial Intelligence in Medicine},
	author = {Zhang, Jian and Shi, Yinghuan and Sun, Jinquan and Wang, Lei and Zhou, Luping and Gao, Yang and Shen, Dinggang},
	year = {2021},
	pages = {101998},
}

@article{lee_scribble2label_2020,
	title = {{Scribble2Label}: {Scribble}-{Supervised} {Cell} {Segmentation} via {Self}-{Generating} {Pseudo}-{Labels} with {Consistency}},
	shorttitle = {{Scribble2Label}},
	url = {http://arxiv.org/abs/2006.12890},
	abstract = {Segmentation is a fundamental process in microscopic cell image analysis. With the advent of recent advances in deep learning, more accurate and high-throughput cell segmentation has become feasible. However, most existing deep learning-based cell segmentation algorithms require fully annotated ground-truth cell labels, which are time-consuming and labor-intensive to generate. In this paper, we introduce Scribble2Label, a novel weakly-supervised cell segmentation framework that exploits only a handful of scribble annotations without full segmentation labels. The core idea is to combine pseudo-labeling and label filtering to generate reliable labels from weak supervision. For this, we leverage the consistency of predictions by iteratively averaging the predictions to improve pseudo labels. We demonstrate the performance of Scribble2Label by comparing it to several state-of-the-art cell segmentation methods with various cell image modalities, including bright-field, fluorescence, and electron microscopy. We also show that our method performs robustly across different levels of scribble details, which confirms that only a few scribble annotations are required in real-use cases.},
	urldate = {2020-11-25},
	journal = {arXiv:2006.12890 [cs]},
	author = {Lee, Hyeonsoo and Jeong, Won-Ki},
	month = jun,
	year = {2020},
	note = {00000 
arXiv: 2006.12890},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, ⛔ No DOI found},
}

@article{chanti_ifss-net_2021,
	title = {{IFSS}-{Net}: {Interactive} {Few}-{Shot} {Siamese} {Network} for {Faster} {Muscle} {Segmentation} and {Propagation} in {Volumetric} {Ultrasound}},
	volume = {40},
	issn = {0278-0062, 1558-254X},
	shorttitle = {{IFSS}-{Net}},
	url = {http://arxiv.org/abs/2011.13246},
	doi = {10/gh4vsp},
	abstract = {We present an accurate, fast and efficient method for segmentation and muscle mask propagation in 3D freehand ultrasound data, towards accurate volume quantification. A deep Siamese 3D Encoder-Decoder network that captures the evolution of the muscle appearance and shape for contiguous slices is deployed. We uses it to propagate a reference mask annotated by a clinical expert. To handle longer changes of the muscle shape over the entire volume and to provide an accurate propagation, we devise a Bidirectional Long Short Term Memory module. Also, to train our model with a minimal amount of training samples, we propose a strategy combining learning from few annotated 2D ultrasound slices with sequential pseudo-labeling of the unannotated slices. We introduce a decremental update of the objective function to guide the model convergence in the absence of large amounts of annotated data. After training with a small number of volumes, the decremental update transitions from a weakly-supervised training to a few-shot setting. Finally, to handle the class-imbalance between foreground and background muscle pixels, we propose a parametric Tversky loss function that learns to adaptively penalize false positives and false negatives. We validate our approach for the segmentation, label propagation, and volume computation of the three low-limb muscles on a dataset of 61600 images from 44 subjects. We achieve a Dice score coefficient of over \$95{\textasciitilde}{\textbackslash}\%\$ and a volumetric error {\textbackslash}textcolor\{black\}\{of\} \$1.6035 {\textbackslash}pm 0.587{\textasciitilde}{\textbackslash}\%\$.},
	number = {10},
	urldate = {2022-01-06},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Chanti, Dawood Al and Duque, Vanessa Gonzalez and Crouzier, Marion and Nordez, Antoine and Lacourpaille, Lilian and Mateus, Diana},
	month = oct,
	year = {2021},
	note = {00000 
arXiv: 2011.13246},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	pages = {2615--2628},
}


@inproceedings{ogier2017individual,
	title = {Individual muscle segmentation in {MR} images: {A} {3D} propagation through {2D} non-linear registration approaches},
	booktitle = {International conference of the {IEEE} engineering in medicine and biology society},
	author = {Ogier, Augustin and Sdika, Michael and Foure, Alexandre and Le Troter, Arnaud and Bendahan, David},
	year = {2017},
	keywords = {⛔ No DOI found},
	doi = {10.1109/EMBC.2017.8036826},
	pages = {317--320},
}

@article{balakrishnan2019voxelmorph,
	title = {{VoxelMorph}: a learning framework for deformable medical image registration},
	volume = {38},
	doi = {10/gfx7zs},
	number = {8},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Balakrishnan, Guha and Zhao, Amy and Sabuncu, Mert R and Guttag, John and Dalca, Adrian V},
	year = {2019},
	note = {Publisher: IEEE},
	pages = {1788--1800},
}